{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa18d66-e876-46e8-a177-d95ca51fea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using sklearn LinearRegression,  StandardScaler test_size=0.2\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "pred=model.predict(X_test_scaled)\n",
    "#print(pred)\n",
    "#print(\"r2_score:\", r2_score(y_test, pred))\n",
    "#print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debf0468-0eea-4d68-9f15-fa47e2f05eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Gradient Descent\n",
    "\n",
    "class BatchGradientDescent:\n",
    "    def __init__(self,learning_rate=0.001 ,iteration=75000, tolerance=1e-10):\n",
    "        self.iteration=iteration\n",
    "        self.tolerance=tolerance\n",
    "        self.learning_rate=learning_rate\n",
    "\n",
    "    def BGDregression(self, X, y):\n",
    "        n_samples=X.shape[0]\n",
    "        n_features=X.shape[1]\n",
    "        theta=np.zeros(n_features)\n",
    "        cost_history=[]\n",
    "\n",
    "        for i in range(self.iteration):\n",
    "            prediction=X@theta\n",
    "            error=prediction-y\n",
    "            cost=(1/(2*n_samples))*np.sum(error**2)\n",
    "            gradient=(1/n_samples)*(X.T@error)\n",
    "            theta-=self.learning_rate*gradient\n",
    "            cost_history.append(cost)\n",
    "        return theta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.column_stack([np.ones(X_train_scaled.shape[0]), X_train_scaled])\n",
    "X_test_scaled = np.column_stack([np.ones(X_test_scaled.shape[0]), X_test_scaled])\n",
    "\n",
    "bgd=BatchGradientDescent()\n",
    "theta=bgd.BGDregression(X_train_scaled, y_train)\n",
    "pred=X_test_scaled@theta\n",
    "#print(pred)\n",
    "#print(\"r2_score:\", r2_score(y_test, pred))\n",
    "#print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f808fcf-b52c-4df3-acf9-801e0f053517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amar_shukla\\AppData\\Local\\Temp\\ipykernel_12968\\3908933593.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  epoch_costs.append(float(cost_i))\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent \n",
    "\n",
    "class SGD:\n",
    "\n",
    "    def __init__(self, epoch=1000, learning_rate=0.01, decay_rate=0.01):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.decay_rate=decay_rate\n",
    "        self.epochs=epoch\n",
    "\n",
    "    def stochastic_gd(self, X, y):\n",
    "\n",
    "        n_samples=X.shape[0]\n",
    "        n_features=X.shape[1]\n",
    "        theta=np.zeros(n_features)\n",
    "        cost_history=[]\n",
    "\n",
    "        t=0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            indices=np.random.permutation(n_samples)\n",
    "            X_shuffled=X[indices]\n",
    "            y_shuffled=y.values[indices]\n",
    "\n",
    "            epoch_costs=[]\n",
    "\n",
    "            for i in range(n_samples):\n",
    "                X_i=X_shuffled[i:i+1]\n",
    "                y_i=y_shuffled[i:i+1]\n",
    "\n",
    "                prediction=X_i@theta\n",
    "\n",
    "                error=prediction-y_i\n",
    "\n",
    "                gradient=X_i.T@error\n",
    "\n",
    "                alpha=self.learning_rate/(1+(self.decay_rate*t))\n",
    "                theta-=alpha*gradient\n",
    "\n",
    "                cost_i=0.5*(error**2)\n",
    "                epoch_costs.append(float(cost_i))\n",
    "\n",
    "                t=t+1\n",
    "            avg_cost_epoch=np.mean(epoch_costs)\n",
    "            cost_history.append(avg_cost_epoch)\n",
    "\n",
    "        return theta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.column_stack([np.ones(X_train_scaled.shape[0]), X_train_scaled])\n",
    "X_test_scaled = np.column_stack([np.ones(X_test_scaled.shape[0]), X_test_scaled])\n",
    "\n",
    "sgd=SGD()\n",
    "theta=sgd.stochastic_gd(X_train_scaled, y_train)\n",
    "pred=X_test_scaled@theta\n",
    "#print(pred)\n",
    "#print(\"r2_score:\", r2_score(y_test, pred))\n",
    "#print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076d00f-ebc8-4386-8bcd-77b49518a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
