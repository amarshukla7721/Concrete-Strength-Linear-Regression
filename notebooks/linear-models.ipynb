{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa18d66-e876-46e8-a177-d95ca51fea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using sklearn LinearRegression,  StandardScaler test_size=0.2\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "pred=model.predict(X_test_scaled)\n",
    "#print(pred)\n",
    "#print(\"r2_score:\", r2_score(y_test, pred))\n",
    "#print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debf0468-0eea-4d68-9f15-fa47e2f05eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Gradient Descent\n",
    "\n",
    "class BatchGradientDescent:\n",
    "    def __init__(self,learning_rate=0.001 ,iteration=75000, tolerance=1e-10):\n",
    "        self.iteration=iteration\n",
    "        self.tolerance=tolerance\n",
    "        self.learning_rate=learning_rate\n",
    "\n",
    "    def BGDregression(self, X, y):\n",
    "        n_samples=X.shape[0]\n",
    "        n_features=X.shape[1]\n",
    "        theta=np.zeros(n_features)\n",
    "        cost_history=[]\n",
    "\n",
    "        for i in range(self.iteration):\n",
    "            prediction=X@theta\n",
    "            error=prediction-y\n",
    "            cost=(1/(2*n_samples))*np.sum(error**2)\n",
    "            gradient=(1/n_samples)*(X.T@error)\n",
    "            theta-=self.learning_rate*gradient\n",
    "            cost_history.append(cost)\n",
    "        return theta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.column_stack([np.ones(X_train_scaled.shape[0]), X_train_scaled])\n",
    "X_test_scaled = np.column_stack([np.ones(X_test_scaled.shape[0]), X_test_scaled])\n",
    "\n",
    "bgd=BatchGradientDescent()\n",
    "theta=bgd.BGDregression(X_train_scaled, y_train)\n",
    "pred=X_test_scaled@theta\n",
    "#print(pred)\n",
    "#print(\"r2_score:\", r2_score(y_test, pred))\n",
    "#print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f808fcf-b52c-4df3-acf9-801e0f053517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amar_shukla\\AppData\\Local\\Temp\\ipykernel_12968\\3908933593.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  epoch_costs.append(float(cost_i))\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent \n",
    "\n",
    "class SGD:\n",
    "\n",
    "    def __init__(self, epoch=1000, learning_rate=0.01, decay_rate=0.01):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.decay_rate=decay_rate\n",
    "        self.epochs=epoch\n",
    "\n",
    "    def stochastic_gd(self, X, y):\n",
    "\n",
    "        n_samples=X.shape[0]\n",
    "        n_features=X.shape[1]\n",
    "        theta=np.zeros(n_features)\n",
    "        cost_history=[]\n",
    "\n",
    "        t=0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            indices=np.random.permutation(n_samples)\n",
    "            X_shuffled=X[indices]\n",
    "            y_shuffled=y.values[indices]\n",
    "\n",
    "            epoch_costs=[]\n",
    "\n",
    "            for i in range(n_samples):\n",
    "                X_i=X_shuffled[i:i+1]\n",
    "                y_i=y_shuffled[i:i+1]\n",
    "\n",
    "                prediction=X_i@theta\n",
    "\n",
    "                error=prediction-y_i\n",
    "\n",
    "                gradient=X_i.T@error\n",
    "\n",
    "                alpha=self.learning_rate/(1+(self.decay_rate*t))\n",
    "                theta-=alpha*gradient\n",
    "\n",
    "                cost_i=0.5*(error**2)\n",
    "                epoch_costs.append(float(cost_i))\n",
    "\n",
    "                t=t+1\n",
    "            avg_cost_epoch=np.mean(epoch_costs)\n",
    "            cost_history.append(avg_cost_epoch)\n",
    "\n",
    "        return theta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.column_stack([np.ones(X_train_scaled.shape[0]), X_train_scaled])\n",
    "X_test_scaled = np.column_stack([np.ones(X_test_scaled.shape[0]), X_test_scaled])\n",
    "\n",
    "sgd=SGD()\n",
    "theta=sgd.stochastic_gd(X_train_scaled, y_train)\n",
    "pred=X_test_scaled@theta\n",
    "#print(pred)\n",
    "#print(\"r2_score:\", r2_score(y_test, pred))\n",
    "#print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2daab96f-216b-4c3b-bad4-d1f1048e32d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (26,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m X_test_scaled = np.column_stack([np.ones(X_test_scaled.shape[\u001b[32m0\u001b[39m]), X_test_scaled])\n\u001b[32m     66\u001b[39m sgd=MBGD()\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m theta=\u001b[43msgd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmini_batch_gd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m pred=X_test_scaled\u001b[38;5;129m@theta\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mMBGD.mini_batch_gd\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     40\u001b[39m         epoch_costs.append(cost_i)\n\u001b[32m     42\u001b[39m         t=t+\u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     avg_cost_epoch=\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_costs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     cost_history.append(avg_cost_epoch)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m theta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\fromnumeric.py:3860\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3857\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3858\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3860\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3861\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\_methods.py:119\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mean\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     arr = \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     is_float16_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    123\u001b[39m     rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (26,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "#Mini Batch Gradient Descent \n",
    "\n",
    "class MBGD:\n",
    "\n",
    "    def __init__(self, epoch=1000, learning_rate=0.01, batch_size=32):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epochs=epoch\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    def mini_batch_gd(self, X, y):\n",
    "\n",
    "        n_samples=X.shape[0]\n",
    "        n_features=X.shape[1]\n",
    "        theta=np.zeros(n_features)\n",
    "        cost_history=[]\n",
    "\n",
    "        t=0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            indices=np.random.permutation(n_samples)\n",
    "            X_shuffled=X[indices]\n",
    "            y_shuffled=y.values[indices]\n",
    "\n",
    "            epoch_costs=[]\n",
    "\n",
    "            for i in range(0,n_samples, self.batch_size):\n",
    "                X_i=X_shuffled[i:i+self.batch_size]\n",
    "                y_i=y_shuffled[i:i+self.batch_size]\n",
    "\n",
    "                prediction=X_i@theta\n",
    "\n",
    "                error=prediction-y_i\n",
    "\n",
    "                gradient=X_i.T@error\n",
    "\n",
    "                \n",
    "                theta-=self.learning_rate*gradient\n",
    "\n",
    "                cost_i=0.5*(error**2)\n",
    "                epoch_costs.append(cost_i)\n",
    "\n",
    "                t=t+1\n",
    "            avg_cost_epoch=np.mean(epoch_costs)\n",
    "            cost_history.append(avg_cost_epoch)\n",
    "\n",
    "        return theta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df=pd.read_csv(r\"https://raw.githubusercontent.com/amarshukla7721/Concrete-Strength-Linear-Regression/refs/heads/main/data/raw/concrete_compressive_strength.csv\")\n",
    "X=df[['Cement','Blast_Furnace_Slag','Fly_Ash','Water','Superplasticizer','Coarse_Aggregate','Fine_Aggregate','Age']]\n",
    "y=df['Concrete_Compressive_Strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.column_stack([np.ones(X_train_scaled.shape[0]), X_train_scaled])\n",
    "X_test_scaled = np.column_stack([np.ones(X_test_scaled.shape[0]), X_test_scaled])\n",
    "\n",
    "sgd=MBGD()\n",
    "theta=sgd.mini_batch_gd(X_train_scaled, y_train)\n",
    "pred=X_test_scaled@theta\n",
    "print(pred)\n",
    "print(\"r2_score:\", r2_score(y_test, pred))\n",
    "print(\"mse:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e512d-7451-440b-b2f7-9132a108e9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
